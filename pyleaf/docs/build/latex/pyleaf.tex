%% Generated by Sphinx.
\def\sphinxdocclass{report}
\documentclass[letterpaper,10pt,english]{sphinxmanual}
\ifdefined\pdfpxdimen
   \let\sphinxpxdimen\pdfpxdimen\else\newdimen\sphinxpxdimen
\fi \sphinxpxdimen=.75bp\relax

\PassOptionsToPackage{warn}{textcomp}
\usepackage[utf8]{inputenc}
\ifdefined\DeclareUnicodeCharacter
% support both utf8 and utf8x syntaxes
\edef\sphinxdqmaybe{\ifdefined\DeclareUnicodeCharacterAsOptional\string"\fi}
  \DeclareUnicodeCharacter{\sphinxdqmaybe00A0}{\nobreakspace}
  \DeclareUnicodeCharacter{\sphinxdqmaybe2500}{\sphinxunichar{2500}}
  \DeclareUnicodeCharacter{\sphinxdqmaybe2502}{\sphinxunichar{2502}}
  \DeclareUnicodeCharacter{\sphinxdqmaybe2514}{\sphinxunichar{2514}}
  \DeclareUnicodeCharacter{\sphinxdqmaybe251C}{\sphinxunichar{251C}}
  \DeclareUnicodeCharacter{\sphinxdqmaybe2572}{\textbackslash}
\fi
\usepackage{cmap}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb,amstext}
\usepackage{babel}
\usepackage{times}
\usepackage[Bjarne]{fncychap}
\usepackage{sphinx}

\fvset{fontsize=\small}
\usepackage{geometry}

% Include hyperref last.
\usepackage{hyperref}
% Fix anchor placement for figures with captions.
\usepackage{hypcap}% it must be loaded after hyperref.
% Set up styles of URL: it should be placed after hyperref.
\urlstyle{same}

\addto\captionsenglish{\renewcommand{\figurename}{Fig.}}
\addto\captionsenglish{\renewcommand{\tablename}{Table}}
\addto\captionsenglish{\renewcommand{\literalblockname}{Listing}}

\addto\captionsenglish{\renewcommand{\literalblockcontinuedname}{continued from previous page}}
\addto\captionsenglish{\renewcommand{\literalblockcontinuesname}{continues on next page}}
\addto\captionsenglish{\renewcommand{\sphinxnonalphabeticalgroupname}{Non-alphabetical}}
\addto\captionsenglish{\renewcommand{\sphinxsymbolsname}{Symbols}}
\addto\captionsenglish{\renewcommand{\sphinxnumbersname}{Numbers}}

\addto\extrasenglish{\def\pageautorefname{page}}

\setcounter{tocdepth}{1}



\title{pyleaf Documentation}
\date{Dec 05, 2018}
\release{1.0.0}
\author{Vishal Sonawane}
\newcommand{\sphinxlogo}{\vbox{}}
\renewcommand{\releasename}{Release}
\makeindex
\begin{document}

\pagestyle{empty}
\maketitle
\pagestyle{plain}
\sphinxtableofcontents
\pagestyle{normal}
\phantomsection\label{\detokenize{index::doc}}
sphinx-quickstart on Mon Dec  3 19:04:20 2018.
You can adapt this file completely to your liking, but it should at least
contain the root \sphinxtitleref{toctree} directive.




\chapter{LeafAreaCalculator}
\label{\detokenize{modules:leafareacalculator}}\label{\detokenize{modules::doc}}

\section{basefunctions module}
\label{\detokenize{basefunctions:module-basefunctions}}\label{\detokenize{basefunctions:basefunctions-module}}\label{\detokenize{basefunctions::doc}}\index{basefunctions (module)@\spxentry{basefunctions}\spxextra{module}}\index{CNNModel() (in module basefunctions)@\spxentry{CNNModel()}\spxextra{in module basefunctions}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{basefunctions:basefunctions.CNNModel}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{basefunctions.}}\sphinxbfcode{\sphinxupquote{CNNModel}}}{}{}
Convolutional Neural network model.
Input is 256 vector input dimensional array as Embedding layer.
Additional layers: Conv1d, MaxPooling, Dense, Flatten,Dense.

Type of class label is categorical crossentropy. Adam Optimizer is selected. Display metric is accuracy.
\begin{quote}\begin{description}
\item[{Returns}] \leavevmode
CNN model which is a prototype of the classification model specified in this method.

\item[{Return type}] \leavevmode
keras.model

\end{description}\end{quote}

\end{fulllineitems}

\index{PROCESS\_IMAGE() (in module basefunctions)@\spxentry{PROCESS\_IMAGE()}\spxextra{in module basefunctions}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{basefunctions:basefunctions.PROCESS_IMAGE}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{basefunctions.}}\sphinxbfcode{\sphinxupquote{PROCESS\_IMAGE}}}{\emph{sample\_name\_list}, \emph{path\_}}{}
Accept the image file name from LeafAreaCalculator and prcoess the passed image by cobverting it to model input vector and processing all pixels in the image.
CNN model ouptput class color labels for every pixel. Simple math is then used to calculate leaf area(green pixels) from green:red ratio of all classified labels.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{sample\_name\_list}} (\sphinxstyleliteralemphasis{\sphinxupquote{string}}) \textendash{} image file name to process

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{path}} (\sphinxstyleliteralemphasis{\sphinxupquote{string}}) \textendash{} default path to search for image

\end{itemize}

\item[{Returns}] \leavevmode
list of useful parameters: image\_file\_name, area in cm\textasciicircum{}2 and ** optional use parameters.

\item[{Return type}] \leavevmode
List

\end{description}\end{quote}

\end{fulllineitems}

\index{RETRAIN\_MODEL\_FROM\_SCRATCH() (in module basefunctions)@\spxentry{RETRAIN\_MODEL\_FROM\_SCRATCH()}\spxextra{in module basefunctions}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{basefunctions:basefunctions.RETRAIN_MODEL_FROM_SCRATCH}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{basefunctions.}}\sphinxbfcode{\sphinxupquote{RETRAIN\_MODEL\_FROM\_SCRATCH}}}{}{}
Retrain the CNN model process entirely from scratch. This is action taken when use uses Tools-\textgreater{}Retrain model from GUI menu.

\end{fulllineitems}

\index{alter\_calc() (in module basefunctions)@\spxentry{alter\_calc()}\spxextra{in module basefunctions}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{basefunctions:basefunctions.alter_calc}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{basefunctions.}}\sphinxbfcode{\sphinxupquote{alter\_calc}}}{\emph{image}}{}
EXtract pixel level information from the passed image. Retrieved (r,g,b) pixel values for every pixel of the image and convert them to hsv values,
for easier seperation of green colored pixels.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\sphinxstyleliteralstrong{\sphinxupquote{image}} (\sphinxstyleliteralemphasis{\sphinxupquote{string}}) \textendash{} name of image file

\item[{Returns}] \leavevmode
List of pixels scanned across the image left top right, top to bottom.

\item[{Return type}] \leavevmode
List of tuples

\end{description}\end{quote}

\end{fulllineitems}

\index{generateClassLabels() (in module basefunctions)@\spxentry{generateClassLabels()}\spxextra{in module basefunctions}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{basefunctions:basefunctions.generateClassLabels}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{basefunctions.}}\sphinxbfcode{\sphinxupquote{generateClassLabels}}}{\emph{sample}, \emph{color}}{}
Generates class labels for all the pixels extracted from an image.
Example: if red.png was fetched, all pixels of this image are labelled ‘red’. Likewise, for all images in the default training folder (test\_images/)
In our default environment, we have green for all kinds of leaf images, red for all red squared, and any other is irrelevant to pur computations.

\end{fulllineitems}

\index{getPixelFromLabel() (in module basefunctions)@\spxentry{getPixelFromLabel()}\spxextra{in module basefunctions}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{basefunctions:basefunctions.getPixelFromLabel}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{basefunctions.}}\sphinxbfcode{\sphinxupquote{getPixelFromLabel}}}{\emph{label}}{}
Function to get the pizel from the class label. This reverse mapping is use to generate an image file fom available class labels.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\sphinxstyleliteralstrong{\sphinxupquote{label}} (\sphinxhref{https://docs.python.org/3/library/functions.html\#int}{\sphinxstyleliteralemphasis{\sphinxupquote{int}}}) \textendash{} class label

\item[{Returns}] \leavevmode
(r,g,b) equivalent of class label color.

\item[{Return type}] \leavevmode
\sphinxhref{https://docs.python.org/3/library/stdtypes.html\#tuple}{tuple}

\end{description}\end{quote}

\end{fulllineitems}

\index{image\_area\_calculator() (in module basefunctions)@\spxentry{image\_area\_calculator()}\spxextra{in module basefunctions}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{basefunctions:basefunctions.image_area_calculator}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{basefunctions.}}\sphinxbfcode{\sphinxupquote{image\_area\_calculator}}}{\emph{basepath}, \emph{sample}}{}
Process the desired image, and extract the pixel level information of every pixel in the image in (h,s,v) format.
Utlizes alter\_calc method to generate (h,s,v) values.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{basepath}} (\sphinxstyleliteralemphasis{\sphinxupquote{string}}) \textendash{} default path of images

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{sample}} (\sphinxstyleliteralemphasis{\sphinxupquote{string}}) \textendash{} name of image file

\end{itemize}

\item[{Returns}] \leavevmode
returns the vector embedding which will be input to CNN model.

\item[{Return type}] \leavevmode
list of lists

\end{description}\end{quote}

\end{fulllineitems}

\index{kerasTokenizerUnit() (in module basefunctions)@\spxentry{kerasTokenizerUnit()}\spxextra{in module basefunctions}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{basefunctions:basefunctions.kerasTokenizerUnit}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{basefunctions.}}\sphinxbfcode{\sphinxupquote{kerasTokenizerUnit}}}{\emph{topbestwords}}{}
Convert the (h,s,v) value of every pixel to a 256 dimensional feature vector that serves as an input to the CNN EMbedding layer.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\sphinxstyleliteralstrong{\sphinxupquote{topbestwords}} \textendash{} maximum dimesion of vector, default: 256

\end{description}\end{quote}

:type integer
:return: 256 dimensional vector
:rtype: np.array

\end{fulllineitems}

\index{load\_model() (in module basefunctions)@\spxentry{load\_model()}\spxextra{in module basefunctions}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{basefunctions:basefunctions.load_model}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{basefunctions.}}\sphinxbfcode{\sphinxupquote{load\_model}}}{}{}
Loads the already available model previously saved on disk.

\end{fulllineitems}

\index{processInputTrain() (in module basefunctions)@\spxentry{processInputTrain()}\spxextra{in module basefunctions}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{basefunctions:basefunctions.processInputTrain}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{basefunctions.}}\sphinxbfcode{\sphinxupquote{processInputTrain}}}{}{}
Function that extracts all training images from default traininf images foled (test\_images/) and converts them into required input vector format for CNN embedding layer.

\end{fulllineitems}

\index{readFromDisk() (in module basefunctions)@\spxentry{readFromDisk()}\spxextra{in module basefunctions}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{basefunctions:basefunctions.readFromDisk}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{basefunctions.}}\sphinxbfcode{\sphinxupquote{readFromDisk}}}{}{}
Reads the previously sored pixel/class label values saved as pickled objects.

\end{fulllineitems}

\index{regular() (in module basefunctions)@\spxentry{regular()}\spxextra{in module basefunctions}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{basefunctions:basefunctions.regular}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{basefunctions.}}\sphinxbfcode{\sphinxupquote{regular}}}{\emph{string\_list}, \emph{class\_labels\_norm}, \emph{finalSequence\_}}{}
Trains CNN model with the passed embedding vectors of the image.
CNN model is trained with 600*600 image dimesions, so 360000 data pointes per training image, for all images in default training images directory, for 10 iterations.
Note: At the time of documenting, the acuarcy of model achieved was 99.5\%.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{string\_list}} \textendash{} Dummy variable. Not used.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{class\_labels\_norm}} (\sphinxstyleliteralemphasis{\sphinxupquote{Vector}}) \textendash{} Normalized class labels for the colors.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{finalSequence}} (\sphinxstyleliteralemphasis{\sphinxupquote{List of vectors.}}) \textendash{} Input embedding vectors for image

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{saveModelToDisk() (in module basefunctions)@\spxentry{saveModelToDisk()}\spxextra{in module basefunctions}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{basefunctions:basefunctions.saveModelToDisk}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{basefunctions.}}\sphinxbfcode{\sphinxupquote{saveModelToDisk}}}{\emph{model}}{}
Saves the currenly used CNN model configuration to disk.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\sphinxstyleliteralstrong{\sphinxupquote{model}} (\sphinxstyleliteralemphasis{\sphinxupquote{keras.CNN model}}) \textendash{} current CNN model

\end{description}\end{quote}

\end{fulllineitems}

\index{saveToDisk() (in module basefunctions)@\spxentry{saveToDisk()}\spxextra{in module basefunctions}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{basefunctions:basefunctions.saveToDisk}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{basefunctions.}}\sphinxbfcode{\sphinxupquote{saveToDisk}}}{\emph{string\_list}, \emph{class\_labels\_norm}, \emph{finalSequence\_}}{}
Saves CNN model configuration and input/output pixel/class\_label values to disk for later use. Utilizes pickle objects for compressed serialized storage.

\end{fulllineitems}



\section{leaf\_area\_calculator\_gui module}
\label{\detokenize{leaf_area_calculator_gui:leaf-area-calculator-gui-module}}\label{\detokenize{leaf_area_calculator_gui::doc}}

\chapter{Installation}
\label{\detokenize{install:installation}}\label{\detokenize{install::doc}}
Download the source package from GitHub repository:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{https}\PYG{p}{:}\PYG{o}{/}\PYG{o}{/}\PYG{n}{github}\PYG{o}{.}\PYG{n}{com}\PYG{o}{/}\PYG{n}{vishal11582285}\PYG{o}{/}\PYG{n}{pyleaf}\PYG{o}{.}\PYG{n}{git}
\end{sphinxVerbatim}

Once downloaded, you should be able to locate the below files and directories:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{all\PYGZus{}photos} \PYG{p}{:} \PYG{n}{All} \PYG{n}{raw} \PYG{n}{images} \PYG{n}{that} \PYG{n}{can} \PYG{n}{be} \PYG{n}{used} \PYG{k}{for} \PYG{n}{processing}
\PYG{n}{limited\PYGZus{}images}\PYG{p}{:} \PYG{n}{Set} \PYG{n}{of} \PYG{n}{limited} \PYG{n}{chosen} \PYG{n}{images} \PYG{k}{for} \PYG{n}{testing} \PYG{n}{purpose}
\PYG{n}{saved\PYGZus{}images}\PYG{p}{:} \PYG{n}{This} \PYG{n}{will} \PYG{n}{be} \PYG{n}{the} \PYG{n}{default} \PYG{n}{save} \PYG{n}{directory}\PYG{o}{.} \PYG{o}{\PYGZlt{}}\PYG{n}{Do} \PYG{o+ow}{not} \PYG{n}{change} \PYG{n}{name} \PYG{n}{of} \PYG{n}{this} \PYG{n}{folder}\PYG{o}{\PYGZgt{}}
\PYG{n}{test\PYGZus{}images}\PYG{p}{:} \PYG{n}{Contains} \PYG{n+nb}{all} \PYG{n}{the} \PYG{n}{test} \PYG{n}{images} \PYG{k}{for} \PYG{n}{training} \PYG{n}{the} \PYG{n}{CNN} \PYG{n}{model} \PYG{k}{for} \PYG{n}{classification} \PYG{n}{task}\PYG{o}{.}

\PYG{n}{model}\PYG{o}{.}\PYG{n}{h5}\PYG{p}{,} \PYG{n}{model}\PYG{o}{.}\PYG{n}{json}\PYG{p}{:} \PYG{n}{Already} \PYG{n}{trained} \PYG{n}{model}\PYG{o}{.} \PYG{n}{Ready} \PYG{k}{for} \PYG{n}{immediate} \PYG{n}{use}\PYG{o}{.}
\end{sphinxVerbatim}

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
Locate the setup.py file
In \PYG{n+nb}{command} prompt, type:
python setup.py build
python setup.py install
\end{sphinxVerbatim}

You should now be able to see the package pyleaf in site\_packages of your Python interpreter.


\chapter{Usage}
\label{\detokenize{install:usage}}
Open up the Python interpreter:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}\PYGZgt{}}\PYG{k+kn}{import} \PYG{n+nn}{pyleaf}
\PYG{n}{should} \PYG{n+nb}{open} \PYG{n}{up} \PYG{n}{the} \PYG{n}{pyleaf} \PYG{n}{GUI} \PYG{k}{for} \PYG{n}{use}\PYG{o}{.}
\end{sphinxVerbatim}


\chapter{GUI Features}
\label{\detokenize{install:gui-features}}
On the GUI Application, you will find various options to get you started right away:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Batch} \PYG{n}{Process}\PYG{p}{:}
\PYG{n}{Select} \PYG{n}{default} \PYG{n}{image} \PYG{n}{folder} \PYG{k+kn}{from} \PYG{n+nn}{File}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{Select} \PYG{n}{Default} \PYG{n}{Image} \PYG{n}{Path}
\PYG{n}{Then} \PYG{n}{select} \PYG{n}{Tools}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{Batch} \PYG{n}{Process} \PYG{n}{to} \PYG{n}{run} \PYG{n}{leaf} \PYG{n}{area} \PYG{n}{analysis} \PYG{n}{on} \PYG{n+nb}{all} \PYG{n}{images} \PYG{o+ow}{in} \PYG{n}{chosen} \PYG{n}{folder}\PYG{o}{.}

\PYG{n}{Single} \PYG{n}{Image} \PYG{n}{Analysis}\PYG{p}{:}
\PYG{n}{Use} \PYG{n}{Select} \PYG{n}{Images} \PYG{n}{button} \PYG{n}{to} \PYG{n}{select} \PYG{n}{one} \PYG{o+ow}{or} \PYG{n}{more} \PYG{n}{image}\PYG{p}{(}\PYG{n}{s}\PYG{p}{)} \PYG{o+ow}{and} \PYG{n}{click} \PYG{n}{Process} \PYG{n}{Images} \PYG{n}{to} \PYG{n}{view} \PYG{n}{the} \PYG{n}{results}\PYG{o}{.}

\PYG{n}{Use} \PYG{n}{the} \PYG{n}{navigation} \PYG{n}{page} \PYG{n}{under} \PYG{n}{original} \PYG{n}{window} \PYG{n}{preview} \PYG{n}{to} \PYG{n}{load} \PYG{n+nb}{all} \PYG{n}{selected} \PYG{n}{images}\PYG{o}{.}

\PYG{n}{Reset} \PYG{n}{Workspace} \PYG{n}{button} \PYG{n}{clears} \PYG{n}{the} \PYG{n}{workspace} \PYG{k}{for} \PYG{n}{a} \PYG{n}{fresh} \PYG{n}{start}\PYG{o}{.}

\PYG{n}{Tools}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{Retrain} \PYG{n}{Model} \PYG{n}{to} \PYG{n}{re}\PYG{o}{\PYGZhy{}}\PYG{n}{train} \PYG{n}{CNN} \PYG{n}{clasification} \PYG{n}{model} \PYG{n}{based} \PYG{n}{on} \PYG{n}{updated} \PYG{n}{training} \PYG{n}{images} \PYG{o+ow}{in} \PYG{n}{test\PYGZus{}images}\PYG{o}{/} \PYG{n}{folder}\PYG{o}{.}

\PYG{n}{Tools}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{View} \PYG{n}{Recent} \PYG{n}{Results} \PYG{n}{to} \PYG{n+nb}{open} \PYG{n}{up} \PYG{n}{a} \PYG{n}{window} \PYG{o+ow}{and} \PYG{n}{view} \PYG{n}{the} \PYG{n}{image} \PYG{o+ow}{and} \PYG{n}{their} \PYG{n}{calculated} \PYG{n}{areas} \PYG{o+ow}{in} \PYG{n}{tabular} \PYG{n+nb}{format}\PYG{o}{.}
\end{sphinxVerbatim}


\chapter{Indices and tables}
\label{\detokenize{index:indices-and-tables}}\begin{itemize}
\item {} 
\DUrole{xref,std,std-ref}{genindex}

\item {} 
\DUrole{xref,std,std-ref}{modindex}

\item {} 
\DUrole{xref,std,std-ref}{search}

\end{itemize}


\renewcommand{\indexname}{Python Module Index}
\begin{sphinxtheindex}
\let\bigletter\sphinxstyleindexlettergroup
\bigletter{b}
\item\relax\sphinxstyleindexentry{basefunctions}\sphinxstyleindexpageref{basefunctions:\detokenize{module-basefunctions}}
\end{sphinxtheindex}

\renewcommand{\indexname}{Index}
\printindex
\end{document}